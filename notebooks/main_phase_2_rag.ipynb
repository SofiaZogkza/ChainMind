{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e8df19",
   "metadata": {},
   "source": [
    "# Phase 2: Phase 2 (Vector DB / RAG setup) - [with Pinecone & GPT-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141d4ab",
   "metadata": {},
   "source": [
    "### Step 1: Set up Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65db7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-8.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting certifi>=2019.11.17 (from pinecone)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting orjson>=3.0.0 (from pinecone)\n",
      "  Using cached orjson-3.11.4-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting pinecone-plugin-assistant<4.0.0,>=3.0.1 (from pinecone)\n",
      "  Using cached pinecone_plugin_assistant-3.0.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pinecone-plugin-interface<0.1.0,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/sofiazogkza/repos/Ironhack/ChainMind/venvSofia/lib/python3.13/site-packages (from pinecone) (2.9.0.post0)\n",
      "Collecting typing-extensions>=3.7.4 (from pinecone)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting urllib3>=1.26.5 (from pinecone)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting requests<3.0.0,>=2.32.3 (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sofiazogkza/repos/Ironhack/ChainMind/venvSofia/lib/python3.13/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Using cached pinecone-8.0.0-py3-none-any.whl (745 kB)\n",
      "Using cached pinecone_plugin_assistant-3.0.1-py3-none-any.whl (280 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached orjson-3.11.4-cp313-cp313-macosx_15_0_arm64.whl (128 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, pinecone-plugin-interface, packaging, orjson, idna, charset_normalizer, certifi, requests, pinecone-plugin-assistant, pinecone\n",
      "\u001b[2K  Attempting uninstall: packaging\n",
      "\u001b[2K    Found existing installation: packaging 25.0\n",
      "\u001b[2K    Uninstalling packaging-25.0:\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/11\u001b[0m [pinecone]/11\u001b[0m [pinecone]plugin-assistant]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 orjson-3.11.4 packaging-24.2 pinecone-8.0.0 pinecone-plugin-assistant-3.0.1 pinecone-plugin-interface-0.0.7 requests-2.32.5 typing-extensions-4.15.0 urllib3-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9a214",
   "metadata": {},
   "source": [
    "### Step 2: Create/Setup/Connect a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9268878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pinecone index 'youtube-chunks' ready ‚Äî region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\", \"us-east-1\")  # default to us-east-1\n",
    "\n",
    "# Create Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Index name\n",
    "index_name = \"youtube-chunks\"\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=PINECONE_ENV\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "print(f\"‚úÖ Pinecone index '{index_name}' ready ‚Äî region: {PINECONE_ENV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea95058",
   "metadata": {},
   "source": [
    "### Step 3: Embed the chunks from the JSON dataset and Upsert them into Pinecone using OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acc638bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pinecone index 'youtube-chunks' ready ‚Äî region: us-east-1\n",
      "Upserted 10/34 chunks...\n",
      "Upserted 20/34 chunks...\n",
      "Upserted 30/34 chunks...\n",
      "üéâ All 34 chunks upserted into Pinecone with summaries!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ------------------------------\n",
    "# Load environment variables\n",
    "# ------------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\", \"us-east-1\")\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize OpenAI client\n",
    "# ------------------------------\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize Pinecone client\n",
    "# ------------------------------\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"youtube-chunks\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "print(f\"‚úÖ Pinecone index '{index_name}' ready ‚Äî region: {PINECONE_ENV}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Load your RAG dataset\n",
    "# ------------------------------\n",
    "dataset_path = \"../output/rag_dataset.json\"\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# ------------------------------\n",
    "# Function: Summarize a text chunk\n",
    "# ------------------------------\n",
    "def summarize_chunk(text):\n",
    "    prompt = f\"Summarize the following text in 1-2 sentences, keeping key details:\\n\\n{text}\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ------------------------------\n",
    "# Upsert chunks with precomputed summaries\n",
    "# ------------------------------\n",
    "for i, item in enumerate(dataset):\n",
    "    try:\n",
    "        # Generate embedding\n",
    "        embedding_response = openai.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=item[\"text_chunk\"]\n",
    "        )\n",
    "        embedding = embedding_response.data[0].embedding\n",
    "\n",
    "        # Precompute summary\n",
    "        summary = summarize_chunk(item[\"text_chunk\"])\n",
    "\n",
    "        # Upsert into Pinecone with summary in metadata\n",
    "        index.upsert(\n",
    "            vectors=[{\n",
    "                \"id\": str(i),\n",
    "                \"values\": embedding,\n",
    "                \"metadata\": {\n",
    "                    \"video_title\": item[\"video_title\"],\n",
    "                    \"url\": item[\"url\"],\n",
    "                    \"start_time\": item[\"start_time\"],\n",
    "                    \"end_time\": item[\"end_time\"],\n",
    "                    \"text_chunk\": item[\"text_chunk\"],\n",
    "                    \"summary\": summary\n",
    "                }\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Upserted {i + 1}/{len(dataset)} chunks...\")\n",
    "            sleep(0.1)  # prevent rate limit\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed for chunk {i}: {e}\")\n",
    "\n",
    "print(f\"üéâ All {len(dataset)} chunks upserted into Pinecone with summaries!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da9cec",
   "metadata": {},
   "source": [
    "# üß™ TESTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00bcebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Build a Blockchain Game Using ChatGPT! (00:03:12.239-00:04:41.270)\n",
      "deploy the smart contracts to a local test blockchain uh which it has already uh helped us to download and walk it through with a step-by-step build the pawn game you guys already know it can do this it could design it and code it connect the game uh with the blockchain so this is going to require us to implement the front encode to interact with the ethereum blockchain this should include functions to authenticate users query the nfts deposit nfts into the wagering smart contract and withdraw the winning so once again it already knows everything it needs to do and we'll do this for us and then also we have uh I have to create a user interface for wallet interaction test the game to play the game and then finally promote the game but there you guys go and like literally if you remove some of these pointless ones like maybe promoting the game and learning the basics here uh this is a nine step process to create an nft game uh absolutely crazy imagine that this existed if AI existed during the last crypto bull market how many more crappy crypto games you've had if you guys are watching this please use the power that I am giving you in this video to create high quality Projects please and also let's change blockchain gaming the whole idea of it and give away all of the stuff that players own for free okay let's do that as well um because because we really need a change when people think when they think of a game connected to the blockchain real ownership should not be associated with scam but right now it is which is really really sad so I told it step one complete uh which is like I know the\n",
      "------\n",
      "How to Build a Blockchain Game (00:00:03.270-00:01:59.429)\n",
      "welcome everybody today i wanna build with you all a little blockchain game we are gonna try to build this within the hour or at least i'm gonna give you all the kind of concepts to builds in less than an hour and you will be able to take that and build any game that you can possibly imagine using any blockchain you like let me jump into i built this first thing i did is i jump into my terminal here and the one thing that is the starting point for anything with third web is to use the third web cli now to invoke the stereo with cli i don't need to download anything or set up anything i just need to run npx third web and if i just run this it will tell me what i can do with the web so here we have a nice size card love that and we can see there's a bunch of options the one that i will start with is create so let's run that npx the web create create will walk me through step-by-step instructions to create either an app like a front-end app or a smart contract when i start a blockchain project like this like a blockchain game i usually start with the contract because that's going to be kind of the kind of my back end if you will it's going to be my engine so i choose contract and let's call it um [Music] workshop demo here and the next thing he asked me is to choose a smart contract framework so hard hat or forge is the two options we have right now and we're about to add more i like forge personally um it's nice and quick it's a bit faster than\n",
      "------\n",
      "How to Build a Blockchain Game Using ChatGPT! (00:01:50.939-00:03:12.229)\n",
      "video so the very first thing that I asked gbt for was are you able to code a game that can write simple smart contracts sign wallets and interact with blockchains like ethereum if you can explain the steps that would be necessary to create a simple pong game requiring an nft to play that must be wagered through a smart contract to enter a game with the winner automatically getting the other players nft so essentially I'm asking it create a step-by-step guide for me exactly what I need to do walk me through it like a baby on how to create a very simple game because we're going to start simple where in order to play you have to have an nft um which hopefully has been given away to everyone for free you have to have an nft and then you play and whoever wins because you entered a smart contract to play gets the other person's nft just a straight uh Winner Takes all simple Style game and this is what it said it's said okay well this is what you're gonna have to do first learn the basics all right I got that down if you guys don't know the basics you can watch through my whole video library uh but honestly you can probably even skip this because it's going to walk you through everything you don't really need to know anything then it says set up a development environment which it can do for us completely create an nft smart contract which it can do for us completely create the wagering smart contract once again in which it can do for us display the uh deploy the smart contracts this is where it's supposed to get a little bit more interesting compile and display uh\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "query = \"How do I create a smart contract for a blockchain game?\"\n",
    "query_embedding = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=query\n",
    ").data[0].embedding\n",
    "\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in results.matches:\n",
    "    print(f\"{match.metadata['video_title']} ({match.metadata['start_time']}-{match.metadata['end_time']})\")\n",
    "    print(match.metadata['text_chunk'])\n",
    "    print(\"------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvSofia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
